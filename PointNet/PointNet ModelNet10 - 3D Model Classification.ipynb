{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13a08a7",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning A.Y. 2022/2023\n",
    "## Final Project: 3D Objects Classification - PointNet model\n",
    "\n",
    "Group members:<br>\n",
    "* *Candon Matteo 2020353*: ICT for Internet and Multimedia (Cybersystems) <br>\n",
    "* *Nicoletti Gianpietro 2053042*: ICT for Internet and Multimedia (Cybersystems) <br>\n",
    "* *Rizzetto Nicola 2052417*: Computer Engineering (Artificial Intelligence and Robotics) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100bbba",
   "metadata": {},
   "source": [
    "## Initial configuration and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb3f7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Platform settings: this is an automatinc decision so, please, don't change the value\n",
    "COLAB = True\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "except:\n",
    "    COLAB = False\n",
    "    \n",
    "\n",
    "#Dataset settings:\n",
    "LOAD_DATASET = True #True if you want to load a precomputed dataset \n",
    "ALREADY_DOWNLOADED = False #True if you have already the dataset in the memory\n",
    "ALREADY_UNZIPPED = False #True if you have already unzipped the dataset in the ./data folder, IF True the value of\n",
    "                        #ALREADY_DOWNLOADED variable will be ignore\n",
    "\n",
    "#Model settings:\n",
    "LOAD_MODEL = False #True if you want load the trained model for XX epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "413a1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "PURPLE = '\\033[95m'\n",
    "CYAN = '\\033[96m'\n",
    "DARKCYAN = '\\033[36m'\n",
    "BLUE = '\\033[94m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "RED = '\\033[91m'\n",
    "BOLD = '\\033[1m'\n",
    "UNDERLINE = '\\033[4m'\n",
    "END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "311298cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if working with colab these are needed\n",
    "if (COLAB):\n",
    "    !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "    !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "\n",
    "    !pip install tensorflow\n",
    "    !pip install trimesh\n",
    "    !pip install open3d\n",
    "\n",
    "import trimesh # useful to load polygonal objects (off files)\n",
    "import glob # useful to read filenames with specific patterns, i.e. chair_****\n",
    "#import open3d\n",
    "\n",
    "# Neural Networks libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchmetrics.classification import MulticlassAccuracy\n",
    "#from torch_geometric.nn import GCNConv,global_max_pool\n",
    "#from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#graph libraries\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "import matplotlib.pyplot as plt\n",
    "import time # used to check the training duration\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#manual set of seed for reproducibility\n",
    "seed = 353\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import urllib.request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77098de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mYou are working on: \u001b[0mcpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(BOLD+\"You are working on: \"+END+str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a2630",
   "metadata": {},
   "source": [
    "## Utility functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9f80b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usefull functions\n",
    "\n",
    "cloud_points = 2048 #number of points to describe an object\n",
    "\n",
    "def dataset(points = cloud_points):\n",
    "    train_points = []\n",
    "    train_labels = []\n",
    "    test_points = []\n",
    "    test_labels = []\n",
    "    classes_map = {}\n",
    "    \n",
    "    #saving all classes' folder paths in list\n",
    "    folders = [dir for dir in sorted(os.listdir(data_dir))if os.path.isdir(data_dir)]\n",
    "    folders_path=[]\n",
    "    for i in range(10):\n",
    "        folders_path.append(glob.glob(os.path.join(data_dir, folders[i])))\n",
    "        \n",
    "        \n",
    "    for i,folder in enumerate(folders_path):\n",
    "        \n",
    "        #storing classes' names into list\n",
    "        \n",
    "        print(i)\n",
    "        print(folder[0])\n",
    "        print(type(folder[0]))\n",
    "        \n",
    "        classes_map[i] = folder[0].split(\"\\\\\")[-1]\n",
    "        \n",
    "        #storing train and test files\n",
    "        train_files = glob.glob(os.path.join(folder[0], \"train/*\"))\n",
    "        test_files = glob.glob(os.path.join(folder[0], \"test/*\"))\n",
    "        \n",
    "        #converting train and test files in cloud points\n",
    "        for j in train_files:\n",
    "            train_points.append(trimesh.load(j).sample(cloud_points))\n",
    "            train_labels.append(i)\n",
    "\n",
    "        for j in test_files:\n",
    "            test_points.append(trimesh.load(j).sample(cloud_points))\n",
    "            test_labels.append(i)\n",
    "\n",
    "    return (np.array(train_points),\n",
    "            np.array(test_points),\n",
    "            np.array(train_labels),\n",
    "            np.array(test_labels),\n",
    "            classes_map)\n",
    "\n",
    "def build_graph(data_points):\n",
    "    \n",
    "    edges = []\n",
    "    \n",
    "    for i in trange(len(data_points)):\n",
    "        \n",
    "        A = kneighbors_graph(data_points[i],mode='distance', n_neighbors = 50).toarray()\n",
    "        indices = np.argpartition(A, 50, axis=1)[:, :50]\n",
    "        edge_indexes = np.stack([np.repeat(np.arange(data_points[i].shape[0]), 50), indices.flatten()])\n",
    "#         A = nx.from_numpy_array(A)\n",
    "#         edges.append(np.asarray(list(A.edges())).T)\n",
    "        edges.append(edge_indexes)\n",
    "        print(edge_indexes.shape)\n",
    "        \n",
    "        del A\n",
    "        del edge_indexes\n",
    "        del indices\n",
    "        gc.collect()\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7a379",
   "metadata": {},
   "source": [
    "## Creating or loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670500b",
   "metadata": {},
   "source": [
    "2048 points: https://www.dropbox.com/s/t5h5nmphju4ni14/dataset_nndl_2048.zip?dl=1 <br>\n",
    "\n",
    "**NOTES:**\n",
    "* dl=1 : force the download of the file;\n",
    "* In order to select the correct dataset you need only to modify the url in the method `urlretrieve(url,name)`\n",
    "* Remember to change the value of `cloud_points` according to the datasets you want use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "694a7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(LOAD_DATASET):\n",
    "    \n",
    "    cloud_points = 2048\n",
    "    \n",
    "    if(not ALREADY_DOWNLOADED and (not ALREADY_UNZIPPED)):\n",
    "        urllib.request.urlretrieve(\"https://www.dropbox.com/s/t5h5nmphju4ni14/dataset_nndl_2048.zip?dl=1\", \"dataset_nndl.zip\")\n",
    "        \n",
    "    if(not ALREADY_UNZIPPED):\n",
    "        with zipfile.ZipFile(\"dataset_nndl.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./data/\")\n",
    "        \n",
    "    #loading the data\n",
    "    data_train = np.load(\"data/train_data.npy\",allow_pickle=True)\n",
    "    data_test = np.load(\"data/test_data.npy\",allow_pickle=True)\n",
    "    edge_train = np.load(\"data/train_edges.npy\",allow_pickle=True)\n",
    "    edge_test = np.load(\"data/test_edges.npy\",allow_pickle=True)\n",
    "    train_labels = np.load(\"data/train_labels.npy\",allow_pickle=True)\n",
    "    test_labels = np.load(\"data/test_labels.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b82add39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not LOAD_DATASET):\n",
    "    data_dir = tf.keras.utils.get_file(\"modelnet.zip\", \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\", extract = True)\n",
    "    data_dir = os.path.join(os.path.dirname(data_dir), \"ModelNet10\")\n",
    "\n",
    "#each class is already divided in train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "070d040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of data example\n",
    "if(not LOAD_DATASET):\n",
    "    mesh = trimesh.load(os.path.join(data_dir,\"chair/train/chair_0003.off\"))\n",
    "    mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0af1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not LOAD_DATASET):\n",
    "    #setting parameters\n",
    "    classes = 10 #number of different kind of objects - non modifiable\n",
    "\n",
    "    # Creating dataset object\n",
    "    data_start_time = time.time()\n",
    "    train_points, test_points, train_labels, test_labels, classes_map = dataset(cloud_points)\n",
    "    data_end_time = time.time()\n",
    "\n",
    "    print(\"Time spent creating the dataset object: \",np.round((data_end_time - data_start_time)/60,2), \" minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28e74006",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not LOAD_DATASET):\n",
    "    \n",
    "    print(len(train_points))\n",
    "    print(len(test_points))\n",
    "\n",
    "    #data_train = add_normals(train_points)\n",
    "    #data_test = add_normals(test_points)\n",
    "\n",
    "    edge_train=build_graph(train_points)\n",
    "    edge_test=build_graph(test_points)\n",
    "\n",
    "    \n",
    "    #removing usless variables to clean the RAM\n",
    "    del train_points\n",
    "    del test_points\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ed2fa",
   "metadata": {},
   "source": [
    "### Saving the dataset into local memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45f0a6",
   "metadata": {},
   "source": [
    "**NOTES:**\n",
    "\n",
    "If you want create a link to be used in this code, compress the .npy files into a single .zip file.<br>\n",
    "Make sure that the structure of the .zip will be:<br>\n",
    "<br>\n",
    "folder.zip<br>\n",
    "--file1.npy<br>\n",
    "--file2.npy<br>\n",
    "-- ...<br>\n",
    "\n",
    "<br>\n",
    "and not something like:<br>\n",
    "<br>\n",
    "folder.zip<br>\n",
    "--inner folder<br>\n",
    "----file1.npy<br>\n",
    "----file2.npy<br>\n",
    "---- ...\n",
    "<br>\n",
    "<br>\n",
    "Mantain these names:\n",
    "\n",
    "* list of points for the train: train_data.npy\n",
    "* list of points for the test: test_data.npy\n",
    "* list of edges for the train: train_edges.npy\n",
    "* list of edges for the test: test_edges.npy\n",
    "* labels for the train: train_labels.npy\n",
    "* labels for the test: test_labels.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d3e3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not LOAD_DATASET):\n",
    "    #list of arrays to array of arrays\n",
    "    train = np.empty(len(edge_train), object)\n",
    "    train[:] = edge_train\n",
    "    test = np.empty(len(edge_test), object)\n",
    "    test[:] = edge_test\n",
    "    \n",
    "    #saving the data\n",
    "    np.save(\"data/train_data.npy\",data_train)\n",
    "    np.save(\"data/test_data.npy\",data_test)\n",
    "    np.save(\"data/train_edges.npy\",train)\n",
    "    np.save(\"data/test_edges.npy\",test)\n",
    "    np.save(\"data/train_labels.npy\",train_labels)\n",
    "    np.save(\"data/test_labels.npy\",test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a749e",
   "metadata": {},
   "source": [
    "## Shuffle and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eb26171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1587c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle of the original data\n",
    "indexes =[i for i in range(len(train_labels))]\n",
    "import random\n",
    "random.shuffle(indexes)\n",
    "\n",
    "data_train = data_train[indexes]\n",
    "train_labels = train_labels[indexes]\n",
    "#edge_train = edge_train[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c18c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation: i.e. adding noise to the data(poistion + normal) but mainaining the same graph and label.\n",
    "# in this case we obtain 3x samples of the original dataset\n",
    "data_train_noise = np.concatenate((data_train,data_train+normal(0,5,size = (len(data_train),2048,6))),axis=0)\n",
    "train_labels_noise = np.concatenate((train_labels,train_labels),axis=0)\n",
    "#edge_train_noise =  np.concatenate((edge_train,edge_train),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8394fc64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#shuffle of the augmented dataset\n",
    "indexes =[i for i in range(len(train_labels_noise))]\n",
    "import random\n",
    "random.shuffle(indexes)\n",
    "\n",
    "data_train_noise = data_train_noise[indexes]\n",
    "train_labels_noise = train_labels_noise[indexes]\n",
    "#edge_train_noise = edge_train_noise[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ff556",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Network functions and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d8c3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.k=k\n",
    "        self.conv1 = nn.Conv1d(k,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape == (bs,n,3)\n",
    "        bs = input.size(0)\n",
    "        xb = F.relu(self.bn1(self.conv1(input)))\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "        pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        flat = nn.Flatten(1)(pool)\n",
    "        xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "        xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "\n",
    "        #initialize as identity\n",
    "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "        if xb.is_cuda:\n",
    "            init=init.cuda()\n",
    "        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4a27465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "    def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31c17723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31582d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id64x64=id64x64.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72d29988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "#cloud_points = 2048 # Number of points to describe an object\n",
    "#classes = 40 # Number of classes in the dataset - set for ModelNet40\n",
    "#batch_size = 32\n",
    "#learning_rate = 0.00025\n",
    "#dropout = 0.5\n",
    "#num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99b09842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNet(\n",
       "  (transform): Transform(\n",
       "    (input_transform): Tnet(\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (feature_transform): Tnet(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (logsoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointnet = PointNet()\n",
    "pointnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11aa644",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "563000aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f4f72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_train_loader, labels_train_loader, val_loader=None,  epochs=4):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(data_train_loader, 0):\n",
    "            inputs = data_train_loader[:][:,0:3]\n",
    "            labels = labels_train_loader \n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 5 == 4:    # print every 10 mini-batches\n",
    "                print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100. * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712dd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8cf5c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8, 5, ..., 7, 5, 5])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc38f674",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-1f38d4df8ae1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(data_train_noise)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpointnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train_loader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata_train_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-885b90c0291c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data_train_loader, labels_train_loader, val_loader, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_train_loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm3x3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm64x64\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpointnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpointnetloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm3x3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm64x64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "#print(data_train_noise)\n",
    "train(model = pointnet, data_train_loader= data_train_noise, labels_train_loader = train_labels_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
